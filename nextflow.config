/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    urlpipe Nextflow config file
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Default config options for all compute environments
----------------------------------------------------------------------------------------
*/

// Global default params, used in configs
params {

    // Input options
    input = null
    input_nanopore_preprocess = null

    // UMI cutoff parameters
    umi_cutoffs = '1,3,5,7,10,30,100' // 0 (no correction) will be added by default
    umi_correction_method = "least_distance" // choose from "least_distance", "mode", "mean"

    // allele number: if 1, need to provide length_cutoff_1_x in the sample sheet; if 2, need to provide both length_cutoff_1_x and length_cutoff_2_x
    allele_number = 1

    // run pipeline with which mode: "default", "merge" ("merge" means that R1 and R2 will be merged first), "nanopore" (long reads), "nanopore_preprocess". If "nanopore_preprocess", will process a single nanopore fastq file: trimming, count bc occurrence, split into either direction, demultiplex
    mode = "default"

    // how to determine the length of the CAG repeat:
    length_mode = "distance_count" // choose from "reference_align", "distance_count"
    // reference_align = "assets/IlluminaMmQ50Trim_Ref.fa" // put inside prep_ref config

    // ref for nanopore mode:
    ref = "assets/ref.fa"

    // which reads to keep: "forward_only", "reverse_only", "both_forward_reverse"
    filter_reads = "both_forward_reverse"

// MultiQC options
    multiqc_config             = null
    multiqc_title              = null
    max_multiqc_email_size     = '25.MB'

    // Boilerplate options
    outdir                     = null
    tracedir                   = "${params.outdir}/pipeline_info"
    publish_dir_mode           = 'symlink'
    publish_dir_fastq          = 'symlink'
    email                      = null
    email_on_fail              = null
    plaintext_email            = false
    monochrome_logs            = false
    help                       = false
    validate_params            = true
    show_hidden_params         = false
    schema_ignore_params       = 'genomes'
    enable_conda               = false

    // Max resource options
    // Defaults only, expecting to be overwritten
    max_memory                 = '400.GB'
    max_cpus                   = 256
    max_time                   = '240.h'

}

profiles {
    debug { process.beforeScript = 'echo $HOSTNAME' }
    conda {
        params.enable_conda    = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    mamba {
        params.enable_conda    = true
        conda.useMamba         = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    docker {
        docker.enabled         = true
        docker.userEmulation   = true
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    singularity {
        singularity.enabled    = true
        singularity.autoMounts = true
        docker.enabled         = false
        podman.enabled         = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    lsf {
        process {
            executor = 'lsf'
            clusterOptions = ''
            queue = 'short'
        }
    }
    local {
        executor {
            queueSize = 3 // to avoid freezing local computer
        }
    }
    podman {
        podman.enabled         = true
        docker.enabled         = false
        singularity.enabled    = false
        shifter.enabled        = false
        charliecloud.enabled   = false
    }
    shifter {
        shifter.enabled        = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        charliecloud.enabled   = false
    }
    charliecloud {
        charliecloud.enabled   = true
        docker.enabled         = false
        singularity.enabled    = false
        podman.enabled         = false
        shifter.enabled        = false
    }
    gitpod {
        executor.name          = 'local'
        executor.cpus          = 16
        executor.memory        = 60.GB
    }
    test      { includeConfig 'conf/test.config'      }
    test_full { includeConfig 'conf/test_full.config' }
}



// Export these variables to prevent local Python/R libraries from conflicting with those in the container
// The JULIA depot path has been adjusted to a fixed path `/usr/local/share/julia` that needs to be used for packages in the container.
// See https://apeltzer.github.io/post/03-julia-lang-nextflow/ for details on that. Once we have a common agreement on where to keep Julia packages, this is adjustable.

env {
    PYTHONNOUSERSITE = 1
    R_PROFILE_USER   = "/.Rprofile"
    R_ENVIRON_USER   = "/.Renviron"
    JULIA_DEPOT_PATH = "/usr/local/share/julia"
}

// Capture exit codes from upstream processes when piping
process.shell = ['/bin/bash', '-euo', 'pipefail']

def trace_timestamp = new java.util.Date().format( 'yyyy-MM-dd_HH-mm-ss')
timeline {
    enabled = true
    file    = "${params.tracedir}/execution_timeline_${trace_timestamp}.html"
}
report {
    enabled = true
    file    = "${params.tracedir}/execution_report_${trace_timestamp}.html"
}
trace {
    enabled = true
    file    = "${params.tracedir}/execution_trace_${trace_timestamp}.txt"
}
dag {
    enabled = true
    file    = "${params.tracedir}/pipeline_dag_${trace_timestamp}.html"
}

manifest {
    name            = 'test/urlpipe'
    author          = 'Kai Hu'
    homePage        = 'https://github.com/test/urlpipe'
    description     = 'UMI-based Repeat Length analysis pipeline.'
    mainScript      = 'main.nf'
    nextflowVersion = '!>=21.10.3'
    version         = '1.0dev'
}

// Load base.config for all pipelines
includeConfig 'conf/base.config'

// Load modules.config for DSL2 module specific options
includeConfig 'conf/modules.config'

// Function to ensure that resource requirements don't go beyond
// a maximum limit
def check_max(obj, type) {
    if (type == 'memory') {
        try {
            if (obj.compareTo(params.max_memory as nextflow.util.MemoryUnit) == 1)
                return params.max_memory as nextflow.util.MemoryUnit
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max memory '${params.max_memory}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'time') {
        try {
            if (obj.compareTo(params.max_time as nextflow.util.Duration) == 1)
                return params.max_time as nextflow.util.Duration
            else
                return obj
        } catch (all) {
            println "   ### ERROR ###   Max time '${params.max_time}' is not valid! Using default value: $obj"
            return obj
        }
    } else if (type == 'cpus') {
        try {
            return Math.min( obj, params.max_cpus as int )
        } catch (all) {
            println "   ### ERROR ###   Max cpus '${params.max_cpus}' is not valid! Using default value: $obj"
            return obj
        }
    }
}
